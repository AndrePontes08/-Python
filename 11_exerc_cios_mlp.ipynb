{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndrePontes08/-Python/blob/main/11_exerc_cios_mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Passo 1: Criar os dados de entrada e saída\n",
        "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([0, 1, 1, 0])\n",
        "\n",
        "# Passo 2: Instanciar o modelo\n",
        "# Topologia: uma hidden layer com 10 neurônios, ativação 'relu' e 1000 iterações\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10,), activation='relu', max_iter=1000, random_state=42)\n",
        "\n",
        "# Passo 3: Treinar o modelo\n",
        "mlp.fit(x, y)\n",
        "\n",
        "# Passo 4: Fazer o predict\n",
        "y_pred = mlp.predict(x)\n",
        "\n",
        "# Passo 5: Comparar os resultados\n",
        "print(\"Vetor real (y):\", y)\n",
        "print(\"Vetor predito (y_pred):\", y_pred)\n",
        "\n",
        "# Verificando a acurácia\n",
        "accuracy = np.mean(y == y_pred)\n",
        "print(\"Acurácia:\", accuracy)\n"
      ],
      "metadata": {
        "id": "DF6t7cNPMjOa",
        "outputId": "6d812541-7301-4d29-c0f0-a7729dc01ac6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vetor real (y): [0 1 1 0]\n",
            "Vetor predito (y_pred): [0 1 1 0]\n",
            "Acurácia: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicação\n",
        "\n",
        "1.   Dados de entrada e saída: O problema do XOR possui dois atributos de entrada\n",
        "(x) e uma saída (y).\n",
        "\n",
        "2.  Topologia da rede:\n",
        "\n",
        "*   hidden_layer_sizes=(2,): Define uma camada escondida com dois neurônios.\n",
        "\n",
        "*   activation='relu': Função de ativação ReLU para não-linearidade.\n",
        "\n",
        "*   max_iter=500: Limita o número de épocas para garantir convergência.\n",
        "\n",
        "\n",
        "\n",
        "3.   Treinamento: O método fit ajusta os pesos da rede.\n",
        "4.   Predição: O método predict retorna as saídas da rede.\n",
        "5.   Comparação: Compara o vetor predito com o esperado, verificando se a rede aprendeu o padrão XOR.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HVfsdotFNcHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar as bibliotecas necessárias\n",
        "import pandas as pd\n",
        "\n",
        "# Caminho do arquivo enviado pelo usuário\n",
        "file_path = 'parkinsons.data'\n",
        "\n",
        "# Carregar o arquivo para verificar as colunas\n",
        "data = pd.read_csv(file_path)\n",
        "data.columns.tolist()  # Listar as colunas para análise\n"
      ],
      "metadata": {
        "id": "fk1Zn3gLfK4h",
        "outputId": "b5ac8d09-0d68-40b9-fc2f-efba091c7261",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['name',\n",
              " 'MDVP:Fo(Hz)',\n",
              " 'MDVP:Fhi(Hz)',\n",
              " 'MDVP:Flo(Hz)',\n",
              " 'MDVP:Jitter(%)',\n",
              " 'MDVP:Jitter(Abs)',\n",
              " 'MDVP:RAP',\n",
              " 'MDVP:PPQ',\n",
              " 'Jitter:DDP',\n",
              " 'MDVP:Shimmer',\n",
              " 'MDVP:Shimmer(dB)',\n",
              " 'Shimmer:APQ3',\n",
              " 'Shimmer:APQ5',\n",
              " 'MDVP:APQ',\n",
              " 'Shimmer:DDA',\n",
              " 'NHR',\n",
              " 'HNR',\n",
              " 'status',\n",
              " 'RPDE',\n",
              " 'DFA',\n",
              " 'spread1',\n",
              " 'spread2',\n",
              " 'D2',\n",
              " 'PPE']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Normalizar todas as colunas (exceto a coluna 'status' e 'name')\n",
        "scaler = MinMaxScaler()\n",
        "features = data.drop(columns=['name', 'status'])\n",
        "normalized_features = scaler.fit_transform(features)\n",
        "\n",
        "# Criar um novo DataFrame com as features normalizadas\n",
        "data_normalized = pd.DataFrame(normalized_features, columns=features.columns)\n",
        "data_normalized['status'] = data['status']\n",
        "\n",
        "# Separar em X (features) e y (target)\n",
        "X = data_normalized.drop(columns=['status'])\n",
        "y = data_normalized['status']\n",
        "\n",
        "# Dividir o dataset em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Instanciar o modelo\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10,), activation='relu', max_iter=1000, random_state=42)\n",
        "\n",
        "# Treinar o modelo\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Fazer predições com os dados de teste\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "# Imprimir o percentual de acerto\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "accuracy_percentage = accuracy * 100\n",
        "accuracy_percentage\n"
      ],
      "metadata": {
        "id": "xc7T1BrZfXpQ",
        "outputId": "a28fd4a9-b6f0-49d7-f243-c7c50d467a91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "89.74358974358975"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O modelo obteve um percentual de acerto de aproximadamente 89,74% na base de teste."
      ],
      "metadata": {
        "id": "Xd3pGSQnfcpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "\n",
        "# 1- Carregar a base de dados Penguins da API do Seaborn\n",
        "penguins = sns.load_dataset('penguins')\n",
        "\n",
        "# 2- Tratar a base de dados:\n",
        "# Remover linhas com valores nulos\n",
        "penguins = penguins.dropna()\n",
        "\n",
        "# Converter colunas categóricas em numéricas usando LabelEncoder\n",
        "for column in ['species', 'island', 'sex']:\n",
        "    le = LabelEncoder()\n",
        "    penguins[column] = le.fit_transform(penguins[column])\n",
        "\n",
        "# 3- Normalizar todas as colunas (exceto a target)\n",
        "# Selecionar colunas numéricas para normalização\n",
        "numerical_cols = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
        "scaler = StandardScaler()\n",
        "penguins[numerical_cols] = scaler.fit_transform(penguins[numerical_cols])\n",
        "\n",
        "# 4- Separar o dataset em X (features) e y (target)\n",
        "X = penguins.drop(columns=['species']) # Features\n",
        "y = penguins['species'] # Target - Espécie do pinguim\n",
        "\n",
        "# 5- Gerar as bases de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 6- Importar o modelo MLP do sklearn (já importado)\n",
        "\n",
        "# 7- Instanciar o modelo\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100, 50), # Duas camadas ocultas com 100 e 50 neurônios\n",
        "                    activation='relu',\n",
        "                    max_iter=1000,\n",
        "                    random_state=42)\n",
        "\n",
        "# 8- Treinar o modelo\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# 9- Fazer o predict\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "# 10- Imprimir o percentual de acerto\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Percentual de acerto na base de teste: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "rNgMdMgXfzXg",
        "outputId": "e605c648-ee19-4354-84a3-02b3b8470ad2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentual de acerto na base de teste: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1- Carregar a base \"phoneme\"\n",
        "url = \"https://raw.githubusercontent.com/tmoura/machinelearning/master/phoneme.data\"\n",
        "phoneme = pd.read_csv(url)\n",
        "\n",
        "# 2- A coluna 0 é o target e 3- Todas as colunas são numéricas e não possui valores nulos\n",
        "\n",
        "# 4- Separar o dataset em X (features) e y (target)\n",
        "X = phoneme.iloc[:, 1:]\n",
        "y = phoneme.iloc[:, 0]\n",
        "\n",
        "# 5- Gerar as bases de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 6- Importar o modelo MLP do sklearn\n",
        "\n",
        "# 7- Instanciar o modelo\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100, 50),\n",
        "                    activation='relu',\n",
        "                    max_iter=1000,\n",
        "                    random_state=42)\n",
        "\n",
        "# 8- Treinar o modelo\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# 9- Fazer o predict\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "# 10- Imprimir o percentual de acerto\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Percentual de acerto na base de teste: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "-w3Yk186ViXm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4efa994c-0042-4399-c7ad-4a8330c795c2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentual de acerto na base de teste: 87.33%\n"
          ]
        }
      ]
    }
  ]
}